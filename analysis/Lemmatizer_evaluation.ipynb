{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('lemmatizer_predictions_lfg_dev.json')\n",
    "poss = list(df['UD_POS'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5081266692102251"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ok_baseline'] = df.lemma == df.orth\n",
    "sum(df['ok_baseline'])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM: matched 53 / 80, accuracy 0.66\n",
      "NOUN: matched 623 / 2516, accuracy 0.25\n",
      "PRON: matched 512 / 983, accuracy 0.52\n",
      "VERB: matched 314 / 2206, accuracy 0.14\n",
      "PUNCT: matched 2574 / 2574, accuracy 1.0\n",
      "AUX: matched 64 / 430, accuracy 0.15\n",
      "ADJ: matched 119 / 819, accuracy 0.15\n",
      "PART: matched 454 / 614, accuracy 0.74\n",
      "ADP: matched 864 / 1060, accuracy 0.82\n",
      "ADV: matched 405 / 604, accuracy 0.67\n",
      "DET: matched 64 / 326, accuracy 0.2\n",
      "PROPN: matched 238 / 403, accuracy 0.59\n",
      "CCONJ: matched 250 / 337, accuracy 0.74\n",
      "SCONJ: matched 123 / 150, accuracy 0.82\n",
      "INTJ: matched 2 / 3, accuracy 0.67\n"
     ]
    }
   ],
   "source": [
    "for POS in poss:\n",
    "    df_pos = df[df['UD_POS']==POS]\n",
    "    score = sum(df_pos['ok_baseline'])\n",
    "    size = len(df_pos)\n",
    "    print(f\"{POS}: matched {score} / {size}, accuracy {round(score/size, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ok'] = df.apply(lambda row: row.lemma in row.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8031285768790538"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['ok'])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM: matched 55 / 80, accuracy 0.69\n",
      "NOUN: matched 2352 / 2516, accuracy 0.93\n",
      "PRON: matched 581 / 983, accuracy 0.59\n",
      "VERB: matched 1805 / 2206, accuracy 0.82\n",
      "PUNCT: matched 2574 / 2574, accuracy 1.0\n",
      "AUX: matched 75 / 430, accuracy 0.17\n",
      "ADJ: matched 472 / 819, accuracy 0.58\n",
      "PART: matched 605 / 614, accuracy 0.99\n",
      "ADP: matched 1034 / 1060, accuracy 0.98\n",
      "ADV: matched 404 / 604, accuracy 0.67\n",
      "DET: matched 79 / 326, accuracy 0.24\n",
      "PROPN: matched 0 / 403, accuracy 0.0\n",
      "CCONJ: matched 337 / 337, accuracy 1.0\n",
      "SCONJ: matched 149 / 150, accuracy 0.99\n",
      "INTJ: matched 3 / 3, accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "for POS in poss:\n",
    "    df_pos = df[df['UD_POS']==POS]\n",
    "    score = sum(df_pos['ok'])\n",
    "    size = len(df_pos)\n",
    "    print(f\"{POS}: matched {score} / {size}, accuracy {round(score/size, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of non-trivial cases only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df[df.orth!=df.lemma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6580825318026683"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df2['ok'])/len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM: matched 2 / 27, accuracy 0.07\n",
      "NOUN: matched 1732 / 1893, accuracy 0.91\n",
      "PRON: matched 69 / 471, accuracy 0.15\n",
      "VERB: matched 1491 / 1892, accuracy 0.79\n",
      "AUX: matched 11 / 366, accuracy 0.03\n",
      "ADJ: matched 358 / 700, accuracy 0.51\n",
      "PART: matched 157 / 160, accuracy 0.98\n",
      "ADP: matched 170 / 196, accuracy 0.87\n",
      "ADV: matched 123 / 199, accuracy 0.62\n",
      "DET: matched 15 / 262, accuracy 0.06\n",
      "PROPN: matched 0 / 165, accuracy 0.0\n",
      "CCONJ: matched 87 / 87, accuracy 1.0\n",
      "SCONJ: matched 26 / 27, accuracy 0.96\n",
      "INTJ: matched 1 / 1, accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "for POS in poss:\n",
    "    df_pos = df2[df2['UD_POS']==POS]\n",
    "    size = len(df_pos)\n",
    "    if size==0:\n",
    "        continue\n",
    "    score = sum(df_pos['ok'])\n",
    "    print(f\"{POS}: matched {score} / {size}, accuracy {round(score/size, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    " * Good scores on nouns, except on proper nouns score is worse then no lemmatization at all \n",
    "     * I suggest to temporarly remove lemmatization of proper nouns\n",
    " * Try to add more rules/exceptions to determiners (this is a closed class of lexemes, in my opinion it is the easiest way to improve accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_det = df[df['UD_POS']=='DET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orth</th>\n",
       "      <th>lemma</th>\n",
       "      <th>UD_POS</th>\n",
       "      <th>predictions</th>\n",
       "      <th>ok_baseline</th>\n",
       "      <th>ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>takimi</td>\n",
       "      <td>taki</td>\n",
       "      <td>DET</td>\n",
       "      <td>[takimi]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10084</th>\n",
       "      <td>swego</td>\n",
       "      <td>swój</td>\n",
       "      <td>DET</td>\n",
       "      <td>[swego]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>nasze</td>\n",
       "      <td>nasz</td>\n",
       "      <td>DET</td>\n",
       "      <td>[nasze]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>to</td>\n",
       "      <td>ten</td>\n",
       "      <td>DET</td>\n",
       "      <td>[to]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10150</th>\n",
       "      <td>tę</td>\n",
       "      <td>ten</td>\n",
       "      <td>DET</td>\n",
       "      <td>[tę]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         orth lemma UD_POS predictions  ok_baseline     ok\n",
       "1002   takimi  taki    DET    [takimi]        False  False\n",
       "10084   swego  swój    DET     [swego]        False  False\n",
       "1012    nasze  nasz    DET     [nasze]        False  False\n",
       "10142      to   ten    DET        [to]        False  False\n",
       "10150      tę   ten    DET        [tę]        False  False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_det[~df_det['ok']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
